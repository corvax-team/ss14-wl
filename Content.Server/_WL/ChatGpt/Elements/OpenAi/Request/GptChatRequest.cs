using System.ComponentModel.DataAnnotations;
using System.Linq;
using System.Text.Json;
using System.Text.Json.Serialization;

namespace Content.Server._WL.ChatGpt.Elements.OpenAi.Request
{
    /// <summary>
    /// Класс запроса к текстовой модели OpenAi
    /// </summary>
    public sealed class GptChatRequest
    {
        /// <summary>
        /// Список сообщений, которые будут отправлены текстовой модели.
        /// Использовать <see cref="GptChatMessage"/>.
        /// <see langword="object"/> тут, потому что ебучий JsonSerializer работаит ни таг каг нада.
        /// </summary>
        [JsonPropertyName("messages")]
        public required object[] Messages { get; set; }

        /// <summary>
        /// Модель, используемая для генерации ответа.
        /// </summary>
        [JsonPropertyName("model")]
        public string Model { get; set; } = null!;

        /// <summary>
        /// Использовать или нет выходные данные модели после запроса для использования в Model Distillation.
        /// <see href="https://platform.openai.com/docs/guides/distillation"/>.
        /// Как я понял..:. улучшает производительность для 'больших' моделей по типу gpt-4o.
        /// <see langword="false"/> по умолчанию.
        /// </summary>
        [JsonPropertyName("store")]
        public bool? Store { get; set; } = false;

        /// <summary>
        /// Вряд ли будет использоваться.
        /// Но: лучше сувать сюда словарь.
        /// Эти метаданные будут использоваться для фильтрации всех ответов в специальном пользовательском UI openAi.
        /// </summary>
        [JsonPropertyName("metadata")]
        public object? Metadata { get; set; }

        /// <summary>
        /// Чем выше значение, тем больше вероятность того. что модель повторит одну и ту же строку в ответе.
        /// Используется только с "памятью".
        /// По умолчанию - <see langword="0f"/>.
        /// </summary>
        [Range(-2.0, 2.0)]
        [JsonPropertyName("frequency_penalty")]
        public double? FrequencyPenalty { get; set; } = 0f;

        //Перепишите это поле блйа, нихуя не понял.
        //Короче, слева номер(?) токена, а справа число принадлежащее [-100, 100], которое влияет на какую-то вероятность(?).
        /// <summary>
        /// Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100.
        /// Mathematically, the bias is added to the logits generated by the model prior to sampling.
        /// The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection;
        /// values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
        /// <see href="https://platform.openai.com/docs/api-reference/chat/create#chat-create-logit_bias"/>.
        /// </summary>
        [JsonPropertyName("logit_bias")]
        public Dictionary<int, int>? LogitBias { get; set; } = null;

        /// <summary>
        /// Надо или нет возвращать подробную информацию о каждом токене в ответе.
        /// <see cref="Response.GptChoice.LogProbs"/>.
        /// </summary>
        [JsonPropertyName("logprobs")]
        public bool? LogProbs { get; set; } = false;

        /// <summary>
        /// Целое число от 0 до 20, определяющее количество наиболее вероятных токенов,
        /// которые будут возвращены в каждой позиции токена, каждый с соответствующей логарифмической вероятностью.
        /// Для <see cref="LogProbs"/> должно быть установлено значение <see langword="true"/>, если используется этот параметр.
        /// </summary>
        [Range(0, 20)]
        [JsonPropertyName("top_logprobs")]
        public int? TopLogProbs { get; set; }

        /// <summary>
        /// Мксимальное количество токенов, которое может быть сгенерировано в отете модели на запрос.
        /// </summary>
        [JsonPropertyName("max_completion_tokens")]
        [Range(0, int.MaxValue)]
        public int? MaxTokens { get; set; }

        /// <summary>
        /// Сколько вариантов ответа предоставит модель при выполнении запроса.
        /// Смотреть <see cref="Response.GptChatResponse.Choices"/>.
        /// По умолчанию - <see langword="1"/>.
        /// </summary>
        [Range(0, int.MaxValue/*Не злоупотребляйте пж*/)]
        [JsonPropertyName("n")]
        public int? N { get; set; } = 1;

        /// <summary>
        /// Чем выше значение, тем больше вероятность того, что модель затронет новую тему.
        /// </summary>
        [Range(-2.0, 2.0)]
        [JsonPropertyName("presence_penalty")]
        public double? PresencePenalty { get; set; } = 0;

        //[JsonPropertyName("response_format")]
        //public object? ReponseFormat;

        /// <summary>
        /// Если указано, то модель при одинаковом сиде будет пытаться ответить на один запрос одинаково.
        /// Находится в бете.
        /// </summary>
        [JsonPropertyName("seed")]
        public int? Seed { get; set; }

        /// <summary>
        /// Массив строк, на которые модель, по сути, должна закончить свой ответ.
        /// "СЛАВА НТ!!!".
        /// </summary>
        [JsonPropertyName("stop")]
        public string[]? Stop { get; set; } = null;

        //[JsonPropertyName("stream")]
        //public bool? Stream;

        /// <summary>
        /// Чем выше значение, тем "случайнее" будет результат.
        /// Если это значение меняется, то менять <see cref="TopP"/> не рекомендуется.
        /// </summary>
        [Range(0.0, 2.0)]
        [JsonPropertyName("temperature")]
        public double? Temperature { get; set; } = 1.0;

        /// <summary>
        /// <see href="https://platform.openai.com/docs/api-reference/chat/create#chat-create-top_p"/>.
        /// </summary>
        [JsonPropertyName("top_p")]
        public double? TopP { get; set; } = 1.0;

        /// <summary>
        /// Уникальный идентификатор пользователя, позволяющий избежать абуза запросов.
        /// Лучше не трогать...
        /// <see href="https://platform.openai.com/docs/api-reference/chat/create#chat-create-user"/>.
        /// </summary>
        [JsonPropertyName("user")]
        public string? User { get; set; }

        /// <summary>
        /// Дать или нет возможность вызывать несколько функций за раз.
        /// Это может повлиять на точность схемы при выборке аргументов для функции, поэтому лучше держать <see langword="false"/>.
        /// Не должно быть <see langword="null"/>, только если <see cref="Tools"/> не равен <see langword="null"/>.
        /// </summary>
        [JsonPropertyName("parallel_tool_calls")]
        public bool? ParallelToolCalls { get; set; } = null;

        /// <summary>
        /// Список функций, которые может вызвать модель в своём ответе.
        /// </summary>
        [JsonPropertyName("tools")]
        public GptChatTool[]? Tools { get; set; } = null;

        /// <summary>
        /// Как модель должна выбрать функцию?
        /// Можно указать, чтобы она не выбирала никаких функций или выбирала конкретную.
        /// Не должно быть <see langword="null"/>, только если <see cref="Tools"/> не равен <see langword="null"/>.
        /// </summary>
        [JsonPropertyName("tool_choice")]
        public string? ModelToolChoice { get; set; } = null;

        /// <summary>
        /// Получает сообщения из объектов типа object в данном типе.
        /// </summary>
        /// <returns></returns>
        public GptChatMessage[] GetMessages()
        {
            return Messages.Select(x => (x as GptChatMessage)!).ToArray();
        }

        #region Utility classes
        /// <summary>
        ///
        /// </summary>
        public static class ToolChoice
        {
            public static string FromType(ToolChoiceType type)
            {
                return type switch
                {
                    ToolChoiceType.Required => "required",
                    ToolChoiceType.None => "none",
                    ToolChoiceType.Auto => "auto",
                    _ => throw new NotImplementedException()
                };
            }

            public static string FromObject(ModelTool.ModelToolType type, string name)
            {
                if (type is ModelTool.ModelToolType.Function)
                {
                    var obj = new
                    {
                        type = ModelTool.FromModelToolType(type),
                        function = new
                        {
                            name
                        }
                    };

                    return Return(obj);
                }

                throw new NotImplementedException();

                static string Return(object obj)
                {
                    return JsonSerializer.Serialize(obj);
                }
            }

            public enum ToolChoiceType : byte
            {
                Auto,
                None,
                Required
            }
        }
        #endregion

        #region Operators
        public static implicit operator GptChatRequest(GptChatMessage[] messages)
        {
            return new GptChatRequest()
            {
                Messages = messages.ToArray()
            };
        }
        #endregion
    }
}
